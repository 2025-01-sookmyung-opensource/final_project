{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUj7qgDZ19rjiYcU0/sOiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2025-01-sookmyung-opensource/final_project/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg27zxxbPGVK"
      },
      "outputs": [],
      "source": [
        "# 1. ÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\n",
        "!pip install -q streamlit pyngrok ultralytics gdown opencv-python pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. pyngrok ÏûÑÌè¨Ìä∏ Î∞è Ïù∏Ï¶ù ÌÜ†ÌÅ∞ ÏÑ§Ï†ï\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrok Ïù∏Ï¶ù ÌÜ†ÌÅ∞ ÎßàÏä§ÌÇπ\n",
        "ngrok.set_auth_token(\"2Np\")\n",
        "\n",
        "# 3. Í∏∞Ï°¥Ïóê Ïó¥Î†§ÏûàÎäî ngrok ÏÑ∏ÏÖò Ï¢ÖÎ£å (Ï§ëÎ≥µ Î∞©ÏßÄ)\n",
        "!pkill -f ngrok"
      ],
      "metadata": {
        "id": "DyLYLB4rQt3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î™®Îç∏ ÌååÏùº Îã§Ïö¥Î°úÎìú\n",
        "import gdown\n",
        "\n",
        "# 1Ï∞® YOLOv8 ÌÉêÏßÄ Î™®Îç∏ Îã§Ïö¥Î°úÎìú\n",
        "gdown.download(id='1sl1dXyWuJiXjhHeacomWwfppsM57VJ85', output='best.pt', quiet=False)\n",
        "\n",
        "# 2Ï∞® MobileNetV3 Ïñë Î∂ÑÎ•ò Î™®Îç∏ Îã§Ïö¥Î°úÎìú\n",
        "gdown.download(id='16Veaxcko0DjfWoSaPqtfe5FVqXxZ25dB', output='quantity_model.pt', quiet=False)"
      ],
      "metadata": {
        "id": "YnO8s56PPRlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üñºÔ∏è app.py Ï†ÄÏû•\n",
        "app_code = r\"\"\"\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ÏÑ§Ï†ï ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "st.set_page_config(page_title='üç± ÏãùÎã® Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑùÍ∏∞', layout='centered')\n",
        "st.title('üç± ÏãùÎã® Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑùÍ∏∞')\n",
        "st.markdown('YOLOv8Î°ú ÏùåÏãùÏùÑ ÌÉêÏßÄÌïòÍ≥†, MobileNetV3Î°ú **Ïñë Îì±Í∏â(Q1~Q5)** ÏùÑ ÏòàÏ∏°Ìï©ÎãàÎã§.')\n",
        "\n",
        "# Îì±Í∏â ÎùºÎ≤®\n",
        "q_labels = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Î™®Îç∏ Î°úÎìú ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    # 1Ï∞® YOLOv8\n",
        "    yolo = YOLO('best.pt')\n",
        "\n",
        "    # 2Ï∞® MobileNetV3\n",
        "    mobilenet = models.mobilenet_v3_small(weights=None)\n",
        "    mobilenet.classifier[3] = nn.Linear(mobilenet.classifier[3].in_features, 5)\n",
        "    mobilenet.load_state_dict(torch.load('quantity_model.pt', map_location='cpu'))\n",
        "    mobilenet.eval()\n",
        "\n",
        "    return yolo, mobilenet\n",
        "\n",
        "yolo_model, quantity_model = load_models()\n",
        "\n",
        "# Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò (MobileNetÏö©)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ÏóÖÎ°úÎìú Ï≤òÎ¶¨ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "uploaded = st.file_uploader(\"Ïù¥ÎØ∏ÏßÄÎ•º ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî\", ['jpg', 'jpeg', 'png'])\n",
        "\n",
        "if uploaded:\n",
        "    pil_img = Image.open(uploaded).convert('RGB')\n",
        "    rgb = np.array(pil_img)\n",
        "    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    st.image(rgb, caption=\"ÏóÖÎ°úÎìúÌïú Ïù¥ÎØ∏ÏßÄ\", use_column_width=True)\n",
        "\n",
        "    # 1Ï∞® ÌÉêÏßÄ (YOLO)\n",
        "    res = yolo_model.predict(bgr, verbose=False)[0]\n",
        "    names = yolo_model.names\n",
        "    cls_ids = res.boxes.cls.cpu().numpy().astype(int)\n",
        "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
        "\n",
        "    st.subheader(\"üçΩÔ∏è Ïù∏ÏãùÎêú ÏùåÏãù Î™©Î°ù\")\n",
        "    if len(cls_ids) == 0:\n",
        "        st.write(\"ÏùåÏãùÏùÑ Ïù∏ÏãùÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§.\")\n",
        "    else:\n",
        "        for i, cid in enumerate(cls_ids):\n",
        "            st.write(f\"- {names[cid]}\")\n",
        "\n",
        "    st.image(res.plot(), caption=\"YOLO Ïù∏Ïãù Í≤∞Í≥º\", use_column_width=True)\n",
        "\n",
        "    st.subheader(\"üìè Ïñë Îì±Í∏â Î∂ÑÏÑù (Q1~Q5)\")\n",
        "    for i, (cid, box) in enumerate(zip(cls_ids, boxes), start=1):\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        crop_rgb = rgb[y1:y2, x1:x2]\n",
        "        if crop_rgb.size == 0:\n",
        "            continue\n",
        "\n",
        "        # Crop ‚Üí PIL ‚Üí Transform\n",
        "        pil_crop = Image.fromarray(crop_rgb)\n",
        "        input_tensor = transform(pil_crop).unsqueeze(0)  # (1, 3, 224, 224)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = quantity_model(input_tensor)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            grade = q_labels[predicted.item()]\n",
        "\n",
        "        st.image(crop_rgb, caption=f\"{i}. {names[cid]} - Ïñë Îì±Í∏â: {grade}\", width=300)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)"
      ],
      "metadata": {
        "id": "2tEolcuaqmmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïã§Ìñâ Î∞è Í≥µÏú†\n",
        "!nohup streamlit run app.py > /dev/null 2>&1 &\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f'Ïï±Ïù¥ Ïã§Ìñâ Ï§ëÏûÖÎãàÎã§: {public_url}')"
      ],
      "metadata": {
        "id": "H3bkVGwEqoFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}