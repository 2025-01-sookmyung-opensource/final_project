import streamlit as st
from PIL import Image
import numpy as np
import pandas as pd
import cv2
from ultralytics import YOLO
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import os

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlitì´ í¬íŠ¸ 8080ì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •
os.environ['PORT'] = '8080'
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_yolo_model():
    return YOLO('best.pt')

@st.cache_resource
def load_portion_model():
    model = models.resnet50(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, 1)  # íšŒê·€ ë˜ëŠ” binary/1-class ë¶„ë¥˜ë¼ë©´ ì¶œë ¥ 1
    state_dict = torch.load('portion_model.pth', map_location='cpu')
    model.load_state_dict(state_dict)
    model.eval()
    return model

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_nutrition_data():
    return pd.read_csv("nutrition_db.csv")

nutrition_df = load_nutrition_data()

# ì „ì²˜ë¦¬
def preprocess_portion_image(image_np):
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    return transform(image_np).unsqueeze(0)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title='ğŸ± ì‹ë‹¨ ì´ë¯¸ì§€ ë¶„ì„ê¸°', layout='centered')
st.title('ğŸ± ì‹ë‹¨ ì´ë¯¸ì§€ ë¶„ì„ê¸°')
st.markdown('ì—…ë¡œë“œí•œ ìŒì‹ ì‚¬ì§„ì—ì„œ **YOLOv8**ìœ¼ë¡œ ìŒì‹ì„ íƒì§€í•˜ê³ , '
            '**ResNet50**ìœ¼ë¡œ ì„­ì·¨ëŸ‰ì„ ì˜ˆì¸¡í•˜ë©°, '
            'ë§¤ì¹­ëœ **ì˜ì–‘ì •ë³´**ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.')

model = load_yolo_model()
portion_model = load_portion_model()

uploaded = st.file_uploader('ğŸ“¤ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”', ['jpg', 'jpeg', 'png'])

if uploaded:
    pil_img = Image.open(uploaded).convert('RGB')
    rgb = np.array(pil_img)
    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)

    st.image(rgb, caption='ğŸ–¼ï¸ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€', use_container_width=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ YOLO íƒì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    res = model.predict(bgr, conf=0.25, verbose=False)[0]
    cls_ids = res.boxes.cls.cpu().numpy().astype(int)
    boxes = res.boxes.xyxy.cpu().numpy()
    names = model.names

    detected = {}
    for cid in cls_ids:
        name = names[cid]
        detected[name] = detected.get(name, 0) + 1

    st.subheader('ğŸ½ï¸ ì¸ì‹ëœ í•­ëª©')
    if detected:
        for name, count in detected.items():
            st.write(f'â€¢ {name}: {count}ê°œ')
    else:
        st.warning('â— ì•„ë¬´ê²ƒë„ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')

    st.image(res.plot(), caption='YOLO íƒì§€ ê²°ê³¼', use_container_width=True)

    if st.download_button(
        label='ğŸ“¥ ê²°ê³¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ',
        data=cv2.imencode('.jpg', res.plot())[1].tobytes(),
        file_name='result.jpg',
        mime='image/jpeg'
    ):
        st.success('ì´ë¯¸ì§€ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤!')

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê°ì²´ë³„ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader('ğŸ” ê°ì²´ë³„ ì„­ì·¨ëŸ‰ + ì˜ì–‘ì •ë³´')

    for i, (cid, box) in enumerate(zip(cls_ids, boxes), start=1):
        x1, y1, x2, y2 = map(int, box)
        crop_rgb = rgb[y1:y2, x1:x2]

        if crop_rgb.size == 0:
            continue

        label = names[cid]
        st.image(crop_rgb, caption=f'{i}. {label}', width=240)

        try:
            # ì„­ì·¨ëŸ‰ ì˜ˆì¸¡
            input_tensor = preprocess_portion_image(crop_rgb)
            with torch.no_grad():
                output = portion_model(input_tensor)
                value = output.item()
            st.success(f'ğŸ½ï¸ ì„­ì·¨ëŸ‰ ì ìˆ˜(íšŒê·€ ì¶œë ¥): **{value:.2f}**')

            # ì˜ì–‘ì •ë³´ ì¶œë ¥
            matched = nutrition_df[nutrition_df['ìŒì‹ëª…'].str.lower() == label.lower()]
            if not matched.empty:
                st.markdown('ğŸ“Š **ì˜ì–‘ ì •ë³´ (1íšŒ ì œê³µëŸ‰ ê¸°ì¤€)**')
                
                nutrition_info = matched.iloc[0][1:]  # ìŒì‹ëª… ì œì™¸
                info_df = pd.DataFrame(nutrition_info).reset_index()
                info_df.columns = ['í•­ëª©', 'ê°’']
                st.table(info_df)  # ë˜ëŠ” st.dataframe(info_df, use_container_width=True)
            else:
                st.info('âš ï¸ ë“±ë¡ëœ ì˜ì–‘ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')


            # YOLO ì¬íƒì§€ (ì„ íƒì )
            crop_bgr = cv2.cvtColor(crop_rgb, cv2.COLOR_RGB2BGR)
            sub = model.predict(crop_bgr, conf=0.25, verbose=False)[0]
            sub_ids = sub.boxes.cls.cpu().numpy().astype(int)
            sub_det = {}
            for sid in sub_ids:
                sname = names[sid]
                sub_det[sname] = sub_det.get(sname, 0) + 1

            if sub_det:
                st.markdown(f'**{i}. ë‚´ë¶€ êµ¬ì„± ë¶„ì„**')
                for sname, count in sub_det.items():
                    st.write(f'â†³ {sname}: {count}ê°œ')

            st.image(sub.plot(), caption=f'{i}. ìƒì„¸ ë¶„ì„ ê²°ê³¼', width=300)

        except Exception as e:
            st.warning(f'âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}')
